{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ed3d6f-5e18-43cc-ac63-e5b38cfdd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a491156-59a9-417e-a94d-3dd99741a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.deep_lstm import DeepLSTM\n",
    "from networks.resnet import ResNet18\n",
    "from networks.FCN import FCN\n",
    "from networks.model import Combined\n",
    "from preprocessing.make_dataset import GestureDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dd5ed5-1608-4032-a2bf-f69548dcb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_loader = torch.load('/mnt/fyp/data/train_loader.pt')\n",
    "val_loader = torch.load('/mnt/fyp/data/val_loader.pt')\n",
    "# device\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57f5e67-0461-4fa1-a82e-3b92976a00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model instantiation\n",
    "input_size_teng = 10  \n",
    "input_size_imu = 18 \n",
    "hidden_size = 128  \n",
    "num_layers = 3 \n",
    "num_classes = 39  \n",
    "\n",
    "resnet18 = ResNet18()\n",
    "lstm_teng = DeepLSTM(input_size_teng, hidden_size, num_layers, 20)\n",
    "lstm_imu = DeepLSTM(input_size_imu, hidden_size, num_layers, 20)\n",
    "\n",
    "fcn_model = FCN(20*3, num_classes)\n",
    "\n",
    "combined_model = Combined(resnet18, lstm_teng, lstm_imu, fcn_model).to(device)\n",
    "\n",
    "# model structure\n",
    "# print(combined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796bf759-d1eb-48d4-aa23-1ce368d98056",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d73daf4-8bc2-4a3e-9794-b604a76ba7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after epoch 1: 72.31%\n",
      "Accuracy after epoch 2: 86.92%\n",
      "Accuracy after epoch 3: 92.31%\n",
      "Accuracy after epoch 4: 93.46%\n",
      "Accuracy after epoch 5: 96.41%\n",
      "Accuracy after epoch 6: 94.87%\n",
      "Accuracy after epoch 7: 97.18%\n",
      "Accuracy after epoch 8: 93.21%\n",
      "Accuracy after epoch 9: 96.67%\n",
      "Accuracy after epoch 10: 97.31%\n",
      "Accuracy after epoch 11: 98.08%\n",
      "Accuracy after epoch 12: 98.46%\n",
      "Accuracy after epoch 13: 98.08%\n",
      "Accuracy after epoch 14: 95.38%\n",
      "Accuracy after epoch 15: 95.51%\n",
      "Accuracy after epoch 16: 96.67%\n",
      "Accuracy after epoch 17: 98.33%\n",
      "Accuracy after epoch 18: 98.33%\n",
      "Accuracy after epoch 19: 97.56%\n",
      "Accuracy after epoch 20: 97.82%\n",
      "Accuracy after epoch 21: 98.72%\n",
      "Accuracy after epoch 22: 96.15%\n",
      "Accuracy after epoch 23: 97.82%\n",
      "Accuracy after epoch 24: 96.92%\n",
      "Accuracy after epoch 25: 98.21%\n",
      "Accuracy after epoch 26: 97.56%\n",
      "Accuracy after epoch 27: 98.59%\n",
      "Accuracy after epoch 28: 97.44%\n",
      "Accuracy after epoch 29: 98.72%\n",
      "Accuracy after epoch 30: 97.95%\n",
      "Accuracy after epoch 31: 98.33%\n",
      "Accuracy after epoch 32: 98.85%\n",
      "Accuracy after epoch 33: 98.33%\n",
      "Accuracy after epoch 34: 98.85%\n",
      "Accuracy after epoch 35: 98.59%\n",
      "Accuracy after epoch 36: 98.72%\n",
      "Accuracy after epoch 37: 98.72%\n",
      "Accuracy after epoch 38: 98.59%\n",
      "Accuracy after epoch 39: 98.85%\n",
      "Accuracy after epoch 40: 99.10%\n",
      "Accuracy after epoch 41: 98.85%\n",
      "Accuracy after epoch 42: 98.72%\n",
      "Accuracy after epoch 43: 93.08%\n",
      "Accuracy after epoch 44: 92.44%\n",
      "Accuracy after epoch 45: 93.72%\n",
      "Accuracy after epoch 46: 98.46%\n",
      "Accuracy after epoch 47: 97.82%\n",
      "Accuracy after epoch 48: 98.85%\n",
      "Accuracy after epoch 49: 98.72%\n",
      "Accuracy after epoch 50: 98.85%\n",
      "Accuracy after epoch 51: 98.59%\n",
      "Accuracy after epoch 52: 98.85%\n",
      "Accuracy after epoch 53: 98.46%\n",
      "Accuracy after epoch 54: 98.97%\n",
      "Accuracy after epoch 55: 98.97%\n",
      "Accuracy after epoch 56: 98.72%\n",
      "Accuracy after epoch 57: 98.97%\n",
      "Accuracy after epoch 58: 98.85%\n",
      "Accuracy after epoch 59: 99.10%\n",
      "Accuracy after epoch 60: 99.10%\n",
      "Accuracy after epoch 61: 99.23%\n",
      "Accuracy after epoch 62: 98.85%\n",
      "Accuracy after epoch 63: 99.10%\n",
      "Accuracy after epoch 64: 98.97%\n",
      "Accuracy after epoch 65: 98.59%\n",
      "Accuracy after epoch 66: 98.97%\n",
      "Accuracy after epoch 67: 98.97%\n",
      "Accuracy after epoch 68: 99.36%\n",
      "Accuracy after epoch 69: 99.23%\n",
      "Accuracy after epoch 70: 99.10%\n",
      "Accuracy after epoch 71: 98.97%\n",
      "Accuracy after epoch 72: 98.85%\n",
      "Accuracy after epoch 73: 98.97%\n",
      "Accuracy after epoch 74: 99.36%\n",
      "Accuracy after epoch 75: 99.36%\n",
      "Accuracy after epoch 76: 99.23%\n",
      "Accuracy after epoch 77: 99.36%\n",
      "Accuracy after epoch 78: 98.72%\n",
      "Accuracy after epoch 79: 93.85%\n",
      "Accuracy after epoch 80: 96.67%\n",
      "Accuracy after epoch 81: 97.82%\n",
      "Accuracy after epoch 82: 97.44%\n",
      "Accuracy after epoch 83: 99.10%\n",
      "Accuracy after epoch 84: 98.46%\n",
      "Accuracy after epoch 85: 99.23%\n",
      "Accuracy after epoch 86: 98.59%\n",
      "Accuracy after epoch 87: 99.23%\n",
      "Accuracy after epoch 88: 99.36%\n",
      "Accuracy after epoch 89: 99.23%\n",
      "Accuracy after epoch 90: 98.97%\n",
      "Accuracy after epoch 91: 99.36%\n",
      "Accuracy after epoch 92: 99.36%\n",
      "Accuracy after epoch 93: 99.36%\n",
      "Accuracy after epoch 94: 99.36%\n",
      "Accuracy after epoch 95: 99.36%\n",
      "Accuracy after epoch 96: 99.36%\n",
      "Accuracy after epoch 97: 99.36%\n",
      "Accuracy after epoch 98: 99.10%\n",
      "Accuracy after epoch 99: 99.23%\n",
      "Accuracy after epoch 100: 99.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.plot(range(1, num_epochs + 1), val_accuracies, marker='o', linestyle='-', color='b')\\nplt.xlabel('Epoch')\\nplt.ylabel('Accuracy')\\nplt.title('Accuracy vs. Epoch')\\nplt.grid(True)\\nplt.savefig('final_img_teng_imu.png')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start to train\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    correct_predictions_train = 0\n",
    "    total_samples_train = 0\n",
    "\n",
    "    combined_model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        img_data = batch['data'][:,:224*224*3].reshape(-1,3,224,224).to(device)\n",
    "        teng_data = batch['data'][:,224*224*3:224*224*3+500].reshape(-1,50,10).to(device) \n",
    "        imu_data = batch['data'][:,224*224*3+500:].reshape(-1,50,18).to(device) \n",
    "        label_data = batch['label'].to(torch.long).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = combined_model(img_data, teng_data, imu_data)    \n",
    "        \n",
    "        label_data = label_data.squeeze()\n",
    "        \n",
    "        loss = criterion(outputs, label_data)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)  \n",
    "        total_samples_train += label_data.size(0)\n",
    "        \n",
    "        correct_predictions_train += (predicted == label_data).sum().item()\n",
    "    \n",
    "    accuracy = correct_predictions_train / total_samples_train\n",
    "\n",
    "    train_accuracies.append(accuracy)\n",
    "    \n",
    "    # eval\n",
    "    \n",
    "    correct_predictions_val = 0\n",
    "    total_samples_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            img_data_val = batch['data'][:,:224*224*3].reshape(-1,3,224,224).to(device)\n",
    "\n",
    "            teng_data_val = batch['data'][:,224*224*3:224*224*3+500].reshape(-1,50,10).to(device) \n",
    "\n",
    "            imu_data_val = batch['data'][:,224*224*3+500:].reshape(-1,50,18).to(device) \n",
    "\n",
    "            label_data_val = batch['label'].to(torch.long).to(device) \n",
    "            label_data_val = label_data_val.squeeze()\n",
    "\n",
    "            outputs_val = combined_model(img_data_val, teng_data_val, imu_data_val)\n",
    "\n",
    "            _, predicted_val = torch.max(outputs_val, 1)  \n",
    "            \n",
    "            total_samples_val += label_data_val.size(0)\n",
    "\n",
    "            correct_predictions_val += (predicted_val == label_data_val).sum().item()\n",
    "\n",
    "        accuracy = correct_predictions_val / total_samples_val\n",
    "\n",
    "        val_accuracies.append(accuracy)\n",
    "\n",
    "        print(f'Accuracy after epoch {epoch + 1}: {accuracy * 100:.2f}%')\n",
    "        combined_model.eval()\n",
    "\n",
    "'''\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Epoch')\n",
    "plt.grid(True)\n",
    "plt.savefig('final_img_teng_imu.png')\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43778f8-2ee1-4642-97a1-b6d1a8138d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "torch.save(combined_model,\"/mnt/fyp/models/img_teng_imu_model.pth\")\n",
    "# save train&val accuracies\n",
    "train_accuracies = torch.tensor(train_accuracies)\n",
    "torch.save(train_accuracies,\"/mnt/fyp/acc/img_teng_imu_train.pth\")\n",
    "val_accuracies = torch.tensor(val_accuracies)\n",
    "torch.save(val_accuracies,\"/mnt/fyp/acc/img_teng_imu_val.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
