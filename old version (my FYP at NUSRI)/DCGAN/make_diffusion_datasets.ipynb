{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8d6d00-5382-4178-b9cb-5b8dac7209c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3066, 12289])\n",
      "torch.Size([3136, 12289])\n",
      "torch.Size([3102, 12289])\n",
      "torch.Size([3081, 12289])\n",
      "torch.Size([3005, 12289])\n",
      "torch.Size([2935, 12289])\n",
      "torch.Size([3038, 12289])\n",
      "torch.Size([3047, 12289])\n",
      "torch.Size([3021, 12289])\n",
      "torch.Size([3017, 12289])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "对于每一类diffusion扩散出来的视觉图像,构建non-shuffle的pt文件\n",
    "'''\n",
    "\n",
    "from torchvision import transforms # first, we need to preprocess(i.e.transform) the train/val sets\n",
    "# then we need to load all the train / val sets\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "rootDir = \"/mnt/visual_sensory_moving2\"\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Resize((64,64)), # 裁剪为224*224\n",
    "    ])\n",
    "\n",
    "labelName = [\"bowl\", \"dog\", \"feel\", \"get\", \"I\", \"know\", \"must\", \"sick\", \"you\", \"zero\"]\n",
    "\n",
    "labelBias = [128, 51, 72, 91, 114, 152, 129, 110, 145, 132]\n",
    "\n",
    "labelCount = [2666, 2736, 2702, 2681, 2605, 2535, 2638, 2647, 2621, 2617]\n",
    "labelCount = [i+400 for i in labelCount] # 最终的图片总数\n",
    "# labelCount = [2794,2787,2774,2772,2719,2687,2767,2757,2766,2749]\n",
    "\n",
    "label = 0\n",
    "trainingRatio = 0.8\n",
    "batchSize = 64\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "    \n",
    "for i in range(len(labelName)):\n",
    "    name = labelName[i] # bowl\n",
    "    bias = labelBias[i]\n",
    "    count = labelCount[i] # 2666+400=3066个\n",
    "    tensorImgSets = []\n",
    "    for j in range(count):\n",
    "        img = Image.open(rootDir+\"/%s/%s%04d.png\" %(name, name, bias+j)) \n",
    "        tensorImg = transforms(img)\n",
    "        tensorImg = tensorImg.reshape((1,-1)) # must be 1 * (3 * 224 * 224)\n",
    "        if j == 0:\n",
    "            tensorImgSets = tensorImg\n",
    "        else:\n",
    "            tensorImgSets = torch.concat((tensorImgSets, tensorImg), dim=0)\n",
    "    \n",
    "    imgLabels = torch.zeros((tensorImgSets.shape[0], 1), dtype=torch.uint8) # tensor.shape[0]:2666/2736/....\n",
    "    imgLabels += label # 矩阵相加,label自动扩展为矩阵\n",
    "    tensorImgSets = torch.concat((tensorImgSets, imgLabels), dim=-1)\n",
    "    print(tensorImgSets.shape)\n",
    "    \n",
    "    label += 1\n",
    "    \n",
    "    torch.save(tensorImgSets,\"/mnt/DCGAN_datasets/nonshuffle_diffusionDatasets_64_{}.pt\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153251c2-2b74-45d2-a509-d6b7315077d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
