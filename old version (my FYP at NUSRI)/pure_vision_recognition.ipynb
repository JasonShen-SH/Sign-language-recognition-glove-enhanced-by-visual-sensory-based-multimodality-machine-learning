{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d80403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bowl', 'dark.mp4', 'dog', 'feel', 'get', 'I', 'know', 'like', 'must', 'sick', 'you']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = 'self_made_signs'\n",
    "signs_class = [cla for cla in os.listdir(file_path)]\n",
    "print(signs_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 训练集train文件夹，并由类名在其目录下创建5个子目录\n",
    "def mkfile(file):\n",
    "    if not os.path.exists(file):\n",
    "        os.makedirs(file)\n",
    "\n",
    "mkfile('signs/train')\n",
    "\n",
    "for cla in signs_class:\n",
    "    mkfile('signs/train/' + cla)\n",
    "\n",
    "mkfile('signs/val')\n",
    "for cla in signs_class:\n",
    "    mkfile('signs/val/' + cla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4128c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分train和val,并构建seperate的train和val集\n",
    "\n",
    "from shutil import copy\n",
    "import random\n",
    " \n",
    "# 划分比例，训练集 : 验证集 \n",
    "split_rate = 1/18\n",
    " \n",
    "# 遍历所有类别的全部图像并按比例分成训练集和验证集\n",
    "for cla in signs_class: #每一个class\n",
    "    cla_path = file_path + '/' + cla + '/'  # 某一类别的子目录\n",
    "    images = os.listdir(cla_path)  # iamges 列表存储了该目录下所有图像的名称\n",
    "    num = len(images)\n",
    "    eval_index = random.sample(images, k=int(num*split_rate)) #从images中，随机抽取k个\n",
    "    #print(eval_index) 随机划分训练和验证集\n",
    "    \n",
    "    for index, image in enumerate(images): #如图像a(1).jpg,那么index是1,image是a(1).jpg\n",
    "        # every image is processed, and is stored to a new folder according to its attribute of train or val\n",
    "\n",
    "        # some old images are val images, they need to store into new folder of val\n",
    "        if image in eval_index:\n",
    "            image_path = cla_path + image #original image path\n",
    "            new_path = 'signs/val/' + cla #new path(val folder)\n",
    "            copy(image_path, new_path)  # old image to new folder\n",
    " \n",
    "        # other old images store into new folder of train\n",
    "        else:\n",
    "            image_path = cla_path + image #original image path\n",
    "            new_path = 'signs/train/' + cla #new path(train folder)\n",
    "            copy(image_path, new_path) # old image to new folder\n",
    "\n",
    "        print(\"\\r[{}] processing [{}/{}]\".format(cla, index + 1, num), end=\"\")  # processing schedule\n",
    "\n",
    "        #\\r:回到行首\n",
    "    \n",
    "    print() #\\n\n",
    " \n",
    "print(\"processing done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bdab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet-18 \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#定义残差块ResBlock\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, identity_downsample=None, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        #这里定义了残差块内连续的2个卷积层\n",
    "        self.conv1 = nn.Conv2d(inchannel,outchannel,kernel_size=3,stride=stride,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(outchannel)\n",
    "        self.conv2 = nn.Conv2d(outchannel,outchannel,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(outchannel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "            \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        # if identity_downsample is not None as default, then:\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        \n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3dc36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet_18, self).__init__()\n",
    "        # self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )  \n",
    "    \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None #默认是none,即identity-free shortcut\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "        #对于64-128.128-256.256-512的第一个block,有stride=2,且outchannel=2*inchannel；\n",
    "        #其他的block,64-64的全部2个,64-128的第2个，128-256的第2个，256-512的第2个，都是outchannel=inchannel\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            ResBlock(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            ResBlock(out_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cda3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_18(3,10)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available () else \"cpu\")\n",
    "\n",
    "model = model.to(device) # or MyNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecfda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms # first, we need to preprocess(i.e.transform) the train/val sets\n",
    "# then we need to load all the train / val sets\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ROOT_TRAIN = r'signs/train'\n",
    "ROOT_TEST = r'signs/val' # test is val in our case\n",
    "\n",
    "# now begin to preprocess(transform)\n",
    "\n",
    "normalize = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)), # 裁剪为224*224\n",
    "    transforms.RandomVerticalFlip(), # 随机垂直旋转\n",
    "    transforms.ToTensor(), # 将0-255范围内的像素转为0-1范围内的tensor\n",
    "    normalize])\n",
    " \n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "# trans are finished, now load the sets(train/val)\n",
    "# two steps to load the sets, 1.load the sets from the path, pure load 2. add important parameters, like batch_size=?, whether to shuffle?\n",
    "# after 2, the packaged sets are ready to input into our self-designed net\n",
    "train_dataset = ImageFolder(ROOT_TRAIN, transform=train_transform)\n",
    "val_dataset = ImageFolder(ROOT_TEST, transform=val_transform)\n",
    " \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c7c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 2, 8, 7, 7, 2, 0, 7, 3, 8, 9, 2, 5, 9, 0, 8])\n",
      "tensor([1, 7, 0, 8, 8, 3, 7, 6, 7, 5, 3, 8, 4, 2, 6, 4])\n",
      "tensor([9, 9, 8, 9, 9, 9, 5, 0, 5, 3, 1, 9, 8, 3, 7, 9])\n",
      "tensor([6, 3, 4, 8, 2, 3, 2, 6, 7, 6, 7, 3, 9, 8, 4, 4])\n",
      "tensor([9, 9, 3, 8, 5, 1, 9, 2, 7, 3, 2, 2, 3, 0, 8, 9])\n",
      "tensor([3, 6, 8, 8, 6, 2, 4, 1, 7, 8, 1, 9, 2, 5, 6, 3])\n",
      "tensor([9, 9, 1, 7, 4, 8, 1, 0, 2, 3, 0, 7, 3, 5, 7, 9])\n",
      "tensor([5, 8, 6, 5, 5, 5, 3, 9, 3, 2, 4, 3, 8, 9, 6, 6])\n",
      "tensor([2, 8, 9, 6, 9, 9, 8, 8, 0, 8, 9, 5, 9, 9, 6, 6])\n",
      "tensor([7, 3, 1, 8, 6, 4, 0, 2, 3, 3, 0, 5, 3, 9, 6, 4])\n",
      "tensor([0, 3, 7, 9, 5, 9, 2, 5, 7, 8, 4, 5, 1, 7, 7, 4])\n",
      "tensor([8, 9, 5, 6, 5, 3, 8, 0, 1, 3, 2, 7, 0, 0, 8, 8])\n",
      "tensor([7, 9, 3, 5, 0, 8, 3, 2, 0, 8, 0, 0, 2, 5, 1, 5])\n",
      "tensor([2, 2, 1, 2, 1, 1, 1, 3, 0, 3, 2, 0, 4, 6, 7, 3])\n",
      "tensor([2, 4, 3, 6, 1, 8, 5, 4, 5, 7, 7, 5, 3, 1, 5, 7])\n",
      "tensor([8, 2, 9, 0, 5, 0, 1, 2, 1, 0, 4, 4, 7, 2, 7, 3])\n",
      "tensor([2, 8, 4, 4, 5, 6, 3, 5, 9, 3, 4, 7, 1, 1, 4, 9])\n",
      "tensor([4, 3, 5, 7, 2, 3, 6, 4, 3, 3, 2, 0, 5, 4, 8, 7])\n",
      "tensor([6, 1, 6, 9, 7, 5, 6, 3, 2, 2, 4, 5, 3, 3, 6, 1])\n",
      "tensor([9, 3, 4, 8, 5, 7, 1, 9, 7, 8, 4, 9, 8, 9, 9, 8])\n",
      "tensor([7, 8, 8, 7, 8, 2, 4, 5, 3, 2, 4, 1, 2, 9, 2, 6])\n",
      "tensor([4, 8, 8, 5, 1, 4, 2, 7, 3, 2, 4, 1, 1, 2, 3, 7])\n",
      "tensor([8, 3, 0, 6, 2, 4, 9, 1, 7, 7, 6, 2, 5, 9, 6, 3])\n",
      "tensor([0, 0, 5, 1, 2, 5, 8, 9, 1, 6, 1, 6, 3, 9, 9, 4])\n",
      "tensor([9, 7, 6, 4, 7, 8, 6, 8, 4, 4, 6, 0, 4, 9, 1, 3])\n",
      "tensor([6, 4, 6, 8, 5, 0, 0, 4, 4, 5, 8, 9, 9, 9, 7, 8])\n",
      "tensor([2, 0, 0, 7, 1, 8, 3, 5, 3, 3, 9, 3, 6, 7, 6, 4])\n",
      "tensor([8, 0, 5, 2, 6, 6, 9, 3, 7, 2, 1, 6, 2, 4, 0, 8])\n",
      "tensor([5, 3, 9, 1, 6, 3, 6, 8, 4, 9, 5, 0, 9, 7, 8, 1])\n",
      "tensor([0, 7, 4, 2, 2, 7, 0, 2, 1, 6, 0, 1, 3, 5, 8, 0])\n",
      "tensor([9, 2, 9, 4, 2, 2, 7, 4, 1, 2, 2, 6, 0, 6, 2, 0])\n",
      "tensor([2, 1, 1, 8, 5, 6, 4, 4, 4, 5, 7, 1, 0, 6, 1, 1])\n",
      "tensor([8, 1, 8, 0, 2, 7, 9, 0, 2, 7, 2, 4, 6, 8, 4, 4])\n",
      "tensor([6, 0, 1, 3, 5, 0, 7, 0, 1, 8, 4, 6, 7, 1, 1, 0])\n",
      "tensor([8, 5, 7, 1, 2, 0, 6, 5, 7, 4, 6, 7, 3, 6, 9, 1])\n",
      "tensor([6, 2, 5, 9, 5, 6, 0, 8, 7, 1, 9, 6, 4, 0, 4, 5])\n",
      "tensor([5, 6, 3, 1, 2, 8, 8, 1, 3, 7, 1, 3, 1, 3, 4, 0])\n",
      "tensor([7, 8, 8, 7, 1, 0, 9, 6, 6, 4, 8, 9, 6, 4, 8, 5])\n",
      "tensor([7, 3, 0, 3, 3, 4, 7, 3, 2, 1, 6, 9, 5, 6, 6, 0])\n",
      "tensor([2, 2, 5, 1, 2, 2, 5, 8, 3, 2, 6, 3, 0, 4, 0, 9])\n",
      "tensor([6, 2, 7, 9, 3, 3, 2, 7, 3, 3, 5, 3, 5, 6, 5, 9])\n",
      "tensor([5, 5, 3, 3, 5, 9, 6, 0, 5, 9, 7, 5, 8, 1, 1, 8])\n",
      "tensor([1, 1, 0, 0, 4, 3, 3, 6, 9, 1, 5, 7, 0, 7, 6, 5])\n",
      "tensor([0, 9, 9, 2, 1, 7, 1, 5, 0, 9, 5, 7, 2, 9, 4, 8])\n",
      "tensor([7, 5, 2, 7, 7, 5, 6, 8, 6, 4, 9, 2, 5, 1, 0, 6])\n",
      "tensor([6, 0, 8, 0, 1, 8, 7, 3, 5, 7, 2, 4, 5, 0, 2, 0])\n",
      "tensor([6, 6, 8, 4, 0, 5, 9, 0, 2, 2, 3, 8, 5, 4, 4, 7])\n",
      "tensor([8, 4, 6, 1, 0, 0, 6, 5, 7, 1, 1, 0, 8, 0, 6, 0])\n",
      "tensor([5, 7, 4, 1, 1, 4, 7, 4, 9, 2, 3, 4, 2, 7, 1, 7])\n",
      "tensor([6, 0, 0, 2, 4, 4, 4, 3, 0, 1, 2, 4, 5, 0, 9, 6])\n",
      "tensor([7, 8, 0, 2, 5, 0, 9, 4, 1, 4, 5, 7, 1, 1, 1, 1])\n",
      "tensor([5, 6, 6, 6, 1, 7, 0, 3, 5, 9, 4, 0, 4, 8, 3, 9])\n",
      "tensor([9, 7, 9, 8, 0, 4, 1, 4, 1, 8, 2, 8, 9, 2, 1, 0])\n",
      "tensor([5, 6])\n"
     ]
    }
   ],
   "source": [
    "for batch_num,(x,label) in enumerate(train_dataloader):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80be8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters of the net:\n",
    "# batch_size has been declared in loading the sets in step 2, the rest are loss_function, optimizer, and learning rate\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6afbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    loss, current, n = 0.0, 0.0, 0\n",
    "    for batch_num, (x, label) in enumerate(dataloader):\n",
    " \n",
    "        # 前向传播\n",
    "        image, label = x.to(device), label.to(device)\n",
    "        output = model(image)\n",
    "        cur_loss = loss_fn(output, label)\n",
    "        _, pred = torch.max(output, axis=1);# print(pred)\n",
    "        cur_acc = torch.sum(label == pred)/output.shape[0]\n",
    " \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        cur_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += cur_loss.item()\n",
    "        current += cur_acc.item()\n",
    "        n = n+1 #n:batch_size数量\n",
    " \n",
    "    # loss和acc是两个不同性质的变量\n",
    "    #loss:损失本身,是一个通过特殊的交叉熵损失函数,得到的连续值\n",
    "    #acc:准确率,是纯粹的正确百分比,例如头三个batch,正确情况为(10/16,5/16,7/16),那么acc=(10+5+7)/(16+16+16),或者acc=(10/16+5/16+7/16)/n (n=3)\n",
    "    train_loss = loss/n\n",
    "    train_acc = current/n\n",
    "    print('train_loss:' + str(train_loss))\n",
    "    print('train_acc:' + str(train_acc))\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb390bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n",
      "--------------\n",
      "train_loss:1.782211630432694\n",
      "train_acc:0.37962962962962965\n",
      "train_loss:  1.782211630432694\n",
      "train_acc:  0.37962962962962965\n",
      "save best model, 第1轮\n",
      "epoch2\n",
      "--------------\n",
      "train_loss:1.0322398532319952\n",
      "train_acc:0.625\n",
      "train_loss:  1.0322398532319952\n",
      "train_acc:  0.625\n",
      "save best model, 第2轮\n",
      "epoch3\n",
      "--------------\n",
      "train_loss:0.7311035952082386\n",
      "train_acc:0.7592592592592593\n",
      "train_loss:  0.7311035952082386\n",
      "train_acc:  0.7592592592592593\n",
      "save best model, 第3轮\n",
      "epoch4\n",
      "--------------\n",
      "train_loss:0.5632679978454554\n",
      "train_acc:0.8206018518518519\n",
      "train_loss:  0.5632679978454554\n",
      "train_acc:  0.8206018518518519\n",
      "save best model, 第4轮\n",
      "epoch5\n",
      "--------------\n",
      "train_loss:0.3715661434387719\n",
      "train_acc:0.8796296296296297\n",
      "train_loss:  0.3715661434387719\n",
      "train_acc:  0.8796296296296297\n",
      "save best model, 第5轮\n",
      "epoch6\n",
      "--------------\n",
      "train_loss:0.3140564936178702\n",
      "train_acc:0.9039351851851852\n",
      "train_loss:  0.3140564936178702\n",
      "train_acc:  0.9039351851851852\n",
      "save best model, 第6轮\n",
      "epoch7\n",
      "--------------\n",
      "train_loss:0.3207841220967196\n",
      "train_acc:0.9039351851851852\n",
      "train_loss:  0.3207841220967196\n",
      "train_acc:  0.9039351851851852\n",
      "epoch8\n",
      "--------------\n",
      "train_loss:0.2972525442364039\n",
      "train_acc:0.9166666666666666\n",
      "train_loss:  0.2972525442364039\n",
      "train_acc:  0.9166666666666666\n",
      "save best model, 第8轮\n",
      "epoch9\n",
      "--------------\n",
      "train_loss:0.21597518771886826\n",
      "train_acc:0.9282407407407407\n",
      "train_loss:  0.21597518771886826\n",
      "train_acc:  0.9282407407407407\n",
      "save best model, 第9轮\n",
      "epoch10\n",
      "--------------\n",
      "train_loss:0.18131987571164412\n",
      "train_acc:0.9421296296296297\n",
      "train_loss:  0.18131987571164412\n",
      "train_acc:  0.9421296296296297\n",
      "save best model, 第10轮\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "loss_train = []\n",
    "acc_train = []\n",
    " \n",
    "epoch = 10\n",
    "max_acc = 0 # the best ever model\n",
    "\n",
    "for t in range(epoch):\n",
    "    print(f\"epoch{t+1}\\n--------------\")\n",
    "    train_loss, train_acc = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    \n",
    "    print(\"train_loss: \",train_loss)\n",
    "    print(\"train_acc: \",train_acc)\n",
    "    \n",
    "    if train_acc > max_acc:\n",
    "        print(f\"save best model, 第{t+1}轮\")\n",
    "        max_acc = train_acc\n",
    "        torch.save(model,\"best_sign_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225ccffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "# val部分不需要损失函数loss_fn和优化器optimizer,只需要求出对不对就行了\n",
    "def test(dataloader, model):\n",
    "    current,n = 0.0,0\n",
    "    for batch_num, (x, label) in enumerate(dataloader):\n",
    "        # 前向传播\n",
    "        image, label = x.to(device), label.to(device)\n",
    "        output = model(image)\n",
    "        _, pred = torch.max(output, axis=1);print(\"label: \",label);print(\"pred: \",pred)\n",
    "        cur_acc = torch.sum(label == pred)/output.shape[0]\n",
    "        \n",
    "        current += cur_acc.item()\n",
    "        n=n+1\n",
    "\n",
    "    test_acc = current/n\n",
    "    print('test_acc:' + str(test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0adc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  tensor([3, 0, 6, 1, 7, 1, 1, 3, 5, 6, 2, 5, 7, 8, 8, 3])\n",
      "pred:  tensor([3, 0, 6, 1, 7, 1, 1, 3, 5, 6, 2, 5, 7, 8, 8, 3])\n",
      "label:  tensor([6, 0, 0, 9, 3, 7, 8, 0, 6, 5, 9, 9, 9, 7, 4, 1])\n",
      "pred:  tensor([3, 0, 0, 9, 3, 7, 8, 0, 6, 5, 9, 9, 9, 7, 4, 1])\n",
      "label:  tensor([8, 9, 5, 1, 4, 8, 2, 2, 2, 4, 7, 6, 4, 3, 5, 2])\n",
      "pred:  tensor([8, 9, 5, 1, 4, 8, 2, 2, 2, 4, 7, 6, 4, 3, 5, 3])\n",
      "label:  tensor([4, 0])\n",
      "pred:  tensor([4, 0])\n",
      "test_acc:0.96875\n"
     ]
    }
   ],
   "source": [
    "#model = ResNet_18(3,10)\n",
    "#model.load_state_sict(torch.load('best_sign_model.pth'))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available () else \"cpu\") ; model = model.to(device) # deploy model on device\n",
    "model.eval() # ready for the test\n",
    "\n",
    "test_acc = test(val_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe84009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试一张图像\n",
    "import cv2\n",
    "for file in os.listdir(\"signs_test\"):\n",
    "    img=cv2.imread(file)\n",
    "    \n",
    "root_test = r'signs_test' # test is val in our case\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_dataset = ImageFolder(root_test, transform=val_transform)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf599cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 4, 5, 8, 3, 7, 0, 9, 6])\n"
     ]
    }
   ],
   "source": [
    "for batch_num,(img,label) in enumerate(test_dataloader):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b20c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  tensor([1, 2, 6, 8, 9, 7, 5, 3, 0, 4])\n",
      "pred:  tensor([3, 2, 3, 3, 9, 3, 3, 3, 0, 3])\n",
      "test_acc:0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "#model = ResNet_18(3,5)\n",
    "#model.load_state_sict(torch.load('best_sign_model.pth'))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available () else \"cpu\") ; model = model.to(device) # deploy model on device\n",
    "model.eval() # ready for the test\n",
    "\n",
    "test_acc = test(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 背景替换\n",
    "import random\n",
    "import os\n",
    "\n",
    "dir_path = \"self_made_signs/bowl/\"\n",
    "\n",
    "percentage_background=0.2\n",
    "\n",
    "sample_num = int(90*percentage_background)\n",
    "\n",
    "nums=[]\n",
    "files= os.listdir(dir_path) \n",
    "for file in files:\n",
    "    file = file[:-4]\n",
    "    file=int(file)\n",
    "    nums.append(file)\n",
    "    \n",
    "random.sample(nums,sample_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
